+++
+++

{{< center title.svg title>}}

## はじめに
AIはあなたを自由にするか？

私の答えは「そんな方向には向かってません！」です。
この結論を理解するのにAIのことが分かる必要はありません。
AIという具体的なテクノロジーについて考えなくても、
そもそも「テクノロジーによってどうなったか」を確認すれば、
その延長線上がどこに向かっているのかは見通せます。

> Artificial intelligence would be the ultimate version of Google. So we have the ultimate search engine that would understand everything on the Web. It would understand exactly what you wanted, and it would give you the right thing.  
AIはGoogleの究極系だ。つまりWeb上の全てを理解した究極のサーチエンジンがあるということだ。それはあなたのほしいものを完全に理解し、あなたに正しいものを与えてくれる。
<cite>by Larry Page<span class="footnote">https://achievement.org/achiever/larry-page/#interview</span></cite>

これは、Googleの創始者ラリー・ペイジの2000年のインタビューでの発言です。
2024年現在でもだいたい同じ考えだと思いますし、
まさにこの発言を実現するような取り組みを進めています。
このテクノロジーの進展はあなたを自由にするでしょうか？

それを説明するために、まずはOpenAI社で発生した騒動から見てみます。

## OpenAI社での騒動
現在、AIは多くの企業によって開発が進められていますが、私企業の実態は詳細には分かりません。
生成系AIとして有名なChatGPTを開発したOpenAI社は他の会社とは異なる背景があり、
内部の様子を垣間見れる騒動がありました。

OpenAIの創立者たちはAIのリスクを認識しており、
その上で2015年にNPO(非営利団体)として設立されました<span class="footnote">現在は営利企業です</span>。
彼らの考えは自分たちがAIの開発をリードして、その力を自分たちが*公正*に使うということでした。
OpenAIの理念には「AIの利益を全人類にもたらすこと」とあります。

2023年11月、OpenAIの取締役会は突然、CEOのサム・アルトマンを解任する決定を下しました。
解任から5日後、アルトマンは復帰し、同時に取締役のメンバーの数人が追い出されました。
この時、OpenAIを去った役員の一人ヘレン・トナーはAIのリスクを専門とする研究者であり、
アルトマン解任の4日前にOpenAIのリスク軽視の姿勢を告発していました<span class="footnote">Decoding Intensions - Artificial Intelligenceand Costly Signals
https://cset.georgetown.edu/wp-content/uploads/CSET-Decoding-Intentions.pdf
</span>。  
この出来事はAIのリスクを差し置いても競争に勝つことが優先される状況に至ったことを如実に示します。
が、私が指摘したいのは、<ins>それ以前から</ins>彼らのAIのリスク認識が
現状の問題をないがしろにしている点です。

OpenAIはAIのリスクを12項目にまとめたシステムカードという文書<span class="footnote">
2024.3.4 GPT-4 Technical Report Appendix H GPT-4 System Card
https://arxiv.org/pdf/2303.08774</span>を発行しています。
10番目の「経済への影響」の項は、政策担当者やステークホルダーが考えるべきことという文から始まり、
「変化があるから気をつけて」程度の記述で深堀りした内容はそこにはありません。  
さらにシステムカードで指摘したいのは、
コンピュータの使用によって膨大な電力を消費している現実に<ins>全く</ins>触れていないことです。
AIのために膨大な電力が使われていることは<ins>今現実に</ins>批判されていることです。

経済問題や環境問題は現在の主要な課題であり、それはテクノロジーの発展によってもたらされたことです。
A.I.は既存のテクノロジーをさらに推し進めたものであり、その影響はさらに大きなものです。
彼らのリスクの提示の姿勢から、これらの問題に彼らが対応することを期待することはできません。
誰の目にも明らかな現在の問題なのに、なぜリスクの専門家さえもそのリスクを直視することができないのでしょうか？

私の考えは以下のとおりです。

{{% definition %}}
現実を見ないからOpenAIの取締役になれるのであって、ちゃんと現実を直視するような人物はOpenAIの取締役にはなれない
{{% /definition %}}

つまり、OpenAIの理念は以前から薄っぺらなものであり、
そんな理念さえも市場原理に流されていく中で受け入れられない状況に至ったと考えます。  
この問題を*みんな*という言葉を使って説明したいと思います。

## *みんな*とは
「みんな」という言葉には二つの使われ方があります。
ひとつは<ins>自身も含めて*みんな*</ins>という場合と<ins>自身は含めずにみんな</ins>という場合です。
本書では<ins>前者</ins>の*みんな*のみ扱います。

*みんな*は「すべての人」や「全人類」を意味しません。
例えば、*みんな*がテクノロジーの恩恵を受けていますが、
すべての人がその恩恵を受けているわけではありません。
*みんな*の中でも大きく恩恵を受けている人もいれば、
それに比べれば無視できるほど小さな恩恵しか受けていなかったり、
むしろ虐げられている人もいます。

人々は*みんな*のために*常識的で公正な責任のある*行動をしています。

### *みんな*は誰かがコントロールしているわけではありません
*みんな*の欲望によってポジションが用意され、そこで求められる通りの振る舞いをする人物がそのポジションに配置されます。  
OpenAIを例にすると、CEOのサム・アルトマンがコントロールしているわけではありません。
OpenAIが業界をリードするための振る舞いがあり、それができているからそのポジションにいるのです。
もしサム・アルトマンが自己を持って*みんな*の求めていない振る舞いをしたら、
OpenAI以外の企業が業界をリードすることになります。

また*みんな*の求める振る舞いは状況次第で変わっていきます。
ヘレン・トナーは就任当初は*みんな*にとって<ins>ちょうどいい</ins>リスクの専門家でしたが、
競争が激化する中で*みんな*の求める振る舞いが変わり退陣することになりました。

### *みんな*は*責任のある*仕事をしています
Googleは<ins>*みんな*の欲しいことを与えること</ins>に成功し、大きく成長しました。
これはGoogle社員の*責任ある*仕事の成果です。
一方でGoogleは<ins>*みんな*の欲しいことを与えた</ins>ために
フィルターバブルが発生し、社会は分断され、それぞれのバブルの中で彼らに都合良い歪んだ現実を見るようになりました。  
Google社員の中にこの現実を危惧し、その流れに抗おうとする社員がいたとすると、
その人は社内的に冷遇され居場所を失うことになります
<span class="footnote">何度かそのような情報を見聞きしたのですが、ソースが思い出せません</span>。
自然と*みんな*と同調できる人が選りすぐられていき、
そのバブルの中では彼らに都合良い歪んだ現実を見ることになります。
そうすることで自らの仕事を*みんな*のための*常識的で公正な責任のある*仕事として続けることができます。

## ようするに
テクノロジーは*みんな*の欲望に応えています。
その結果の一面が膨大なエネルギーの消費であり、環境の破壊です。
またシステムは巨大化し、個人の無力感を生むことになりました。
*みんな*と合致するほど恩恵を受けやすく、
*みんな*とは異なる**自己**を持つほど経済合理性などの圧力がかかり、
不利な状況に置かれることになります。
テクノロジーが便利で広く生活に根ざすほど、その合理性の引力は増加し、**中央**と**周縁**の格差を生みます。

テクノロジーが*みんな*の欲望に応えるほど、あなたが自由になることを妨げていると言えます。
テクノロジーは道具であり、それがどのように便益と損失をもたらすかはそれを使う側の能力の問題です。
現在、人類はテクノロジーを使いこなせていません。
むしろそれに支配されている現実を認識し、そこから解放されることが必要です。
現在のテクノロジーも使いこなせないままならば、
さらに強力なテクノロジーであるAIはその脅威を増幅させることは明白です。  
あなたがAIを自由に使うためには、個々人がテクノロジーをコントロールすることが必要です。
それを社会レベルでいうと自治が必要ということになります。

テクノロジーは*みんな*の欲望に応えるからよいものとみなされており、
そのために様々な問題を引き起こしています。
つまり、これらの問題は*みんな*の*常識的で公正な*日常が原因です。
おかしな*常識*に基づいて、
責任の所在となる*悪者*を見つけて、そいつをやっつけても何も解決するわけではありません。  
問題の解決は私たちの常識<span class="footnote">これは色のつけ忘れではありません。常識があることが問題なのではなく、現在の*常識*がおかしいのです。</span>の書き換えによってなされます。
既存の*常識*に抗う生き方は**中央**からの自立を意味しますが、
バラバラに独立しても非合理を押し付けられ消耗してしまいます。
**周縁**の様々な人々が連帯し独立したもの同士がつながる場を醸成する必要があります。

**周縁**にいる理由は人それぞれですが、
非合理性を押し付けられても尚そこにいる理由があり、多様な物語があります。
冒頭のラリー・ペイジの発言は、Web上の全てを理解した程度であなたのほしいものを完全に理解できる気になっている所に彼の視界の外にあるものへの想像が欠けているように感じます。
そもそも、あなたが「本当に」欲しい物は誰も知らないし、
それはあなた個人だけで分かることでもありません。
それは多くの不確実性をはらむ多様で豊かな社会が作る混沌の中からあなたが見つけるものです。  
混沌の話を含め、より詳細な議論を知りたい方は「生知能論」( https://mzo.kuku9.net/namachi )を参照してください。
こちらでは、現在のAIがどんな仕組みであるか、それと人間の知能と類似性と違いを提示した上で、
その社会的なインパクトを考察しています。

感想、批判、ここが分からない、自分ならこう書く、その他お気づきの点などあれば下記までお気軽にご連絡をお願いします。

{{% definition %}}
email: <a href="mailto:namachi@kuku9.net">namachi@kuku9.net</a>  
mastodon: <a href="https://kolektiva.social/@mzo">@mzo@kolektiva.social </a>  

もしくは<a href="https://lib.kuku9.net/survey/index.php/521887?lang=ja"><ins>こちらの回答フォーム</ins></a>から匿名アンケートにご協力いただけますと幸いです。
{{% /definition %}}
